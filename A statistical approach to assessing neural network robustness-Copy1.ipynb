{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "((train_x, train_y),(eval_x, eval_y)) = tf.keras.datasets.mnist.load_data()\n",
    "train_x = train_x/np.float32(255)\n",
    "eval_x = eval_x/np.float32(255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Helper Functions</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HParams(object):\n",
    "    def __init__(self, **kwargs):\n",
    "        self.dict_ = kwargs\n",
    "        self.__dict__.update(self.dict_)\n",
    "\n",
    "    def update_config(self, in_string):\n",
    "        pairs = in_string.split(\",\")\n",
    "        pairs = [pair.split(\"=\") for pair in pairs]\n",
    "        for key, val in pairs:\n",
    "            self.dict_[key] = type(self.dict_[key])(val)\n",
    "        self.__dict__.update(self.dict_)\n",
    "        return self\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        return self.dict_[key]\n",
    "\n",
    "    def __setitem__(self, key, val):\n",
    "        self.dict_[key] = val\n",
    "        self.__dict__.update(self.dict_)\n",
    "\n",
    "\n",
    "def get_default_hparams():\n",
    "    return HParams(\n",
    "        image_dim = 28,\n",
    "        epoch_num = 50,\n",
    "        batch_size = 1000,\n",
    "        learning_rate = 1e-3,\n",
    "        next_batch = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_pool(inputs, filters=32, kernel_size=[5,5], pool_size=[2,2]):\n",
    "    conv = tf.layers.conv2d(\n",
    "        inputs=inputs,\n",
    "        filters=filters,\n",
    "        kernel_size=kernel_size,\n",
    "        padding=\"same\",\n",
    "        activation=tf.nn.relu)\n",
    "    pool = tf.layers.max_pooling2d(inputs=conv, pool_size=pool_size, strides=2)\n",
    "    return pool\n",
    "\n",
    "def dense_layer(inputs, reshape=(7,7,64), units=1024, drop_out=True, drop_out_rate=0.4, training=True):\n",
    "    inputs = tf.reshape(inputs, [-1, reshape[0]*reshape[1]*reshape[2]])\n",
    "    dense = tf.layers.dense(inputs=inputs, units=units, activation=tf.nn.relu)\n",
    "    dropout = tf.layers.dropout(inputs=dense, rate=drop_out_rate, training=training)\n",
    "    return dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model(inputs, training=True):\n",
    "    with tf.variable_scope(\"cnn_model\", reuse=tf.AUTO_REUSE):\n",
    "        inputs = tf.expand_dims(inputs, 3)\n",
    "        conv1 = conv_pool(inputs)\n",
    "        conv2 = conv_pool(conv1, filters=64)\n",
    "        dense = dense_layer(conv2, training=training)\n",
    "        logits = tf.layers.dense(inputs=dense, units=10)\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(data, batch_num, batch_size=100):\n",
    "    if batch_size == 0:\n",
    "        raise ValueError(\"batch_size cannot be zero\")\n",
    "    elif batch_num < 0:\n",
    "        raise ValueError(\"batch_num must be larger than or equal to zero\")\n",
    "    elif data is np.ndarray:\n",
    "        raise TypeError(\"input data should be numpy.ndarray\")\n",
    "    elif data.shape[0] < batch_size:\n",
    "        raise TypeError(\"please reduce the batch_size less than the data number\")\n",
    "    number_of_batch = data.shape[0]//batch_size\n",
    "    if batch_num >= number_of_batch:\n",
    "        end_of_batch = True\n",
    "    else:\n",
    "        end_of_batch = False\n",
    "    batch_num = batch_num % number_of_batch\n",
    "    return data[batch_num*batch_size:(batch_num+1)*batch_size], end_of_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(train_x, train_y, hps, \n",
    "             restore=False, save=False, clean_graph=False, \n",
    "             sess=tf.Session(), path=\"./trained_model\", filename=\"model.ckpt\"):\n",
    "    inputs = tf.placeholder(tf.float32, shape=(None, hps.image_dim, hps.image_dim))\n",
    "    labels = tf.placeholder(tf.int32, shape=(None))\n",
    "    logits = cnn_model(inputs)\n",
    "    loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=hps.learning_rate).minimize(loss)\n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "    sess.run([tf.global_variables_initializer()])\n",
    "    if restore:\n",
    "        saver.restore(sess, \"{0}/{1}\".format(path, filename))\n",
    "\n",
    "    for epoch in range(hps.epoch_num):\n",
    "        next_batch = hps.next_batch\n",
    "        while True:\n",
    "            train_data, end_of_batch = get_batch(train_x, batch_size=hps.batch_size, batch_num=next_batch)\n",
    "            train_labels, _ = get_batch(train_y, batch_size=hps.batch_size, batch_num=next_batch)\n",
    "            next_batch += 1\n",
    "            sess.run(optimizer, feed_dict={inputs: train_data, labels: train_labels})\n",
    "            loss_run_time = sess.run(loss, feed_dict={inputs: train_data, labels: train_labels})\n",
    "            if end_of_batch:\n",
    "                break\n",
    "        print(\"Epoch: {}, Loss:{}\".format(epoch, loss_run_time))\n",
    "    if save:\n",
    "        save_path = saver.save(sess, \"{0}/{1}\".format(path, filename))\n",
    "        print(\"Model is saved to {0}\".format(save_path))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(eval_x, eval_y, hps, \n",
    "               sess=tf.Session(),\n",
    "               path=\"./trained_model\", filename=\"model.ckpt\", print_output=True):\n",
    "    inputs = tf.placeholder(tf.float32, shape=(None, hps.image_dim, hps.image_dim))\n",
    "    labels = tf.placeholder(tf.int32, shape=(None))\n",
    "    logits = cnn_model(inputs, training=False)\n",
    "    loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
    "    saver = tf.train.Saver()\n",
    "    sess.run([tf.global_variables_initializer()])\n",
    "    saver.restore(sess, \"./trained_model/model.ckpt\")\n",
    "    loss_run_time, logits_run_time = sess.run([loss, logits], feed_dict={inputs: eval_x, labels: eval_y})\n",
    "    accuracy = 100 * np.sum(np.argmax(logits_run_time, axis=1) == eval_y) / eval_y.shape[0]\n",
    "    if print_output:\n",
    "        print(\"Loss:{}, Accuracy:{}%\".format(loss_run_time, accuracy))\n",
    "    return logits_run_time, eval_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_model(hps, \n",
    "               sess=tf.Session(),\n",
    "               path=\"./trained_model\", \n",
    "               filename=\"model.ckpt\"):\n",
    "    inputs = tf.placeholder(tf.float32, shape=(None, hps.image_dim, hps.image_dim))\n",
    "    labels = tf.placeholder(tf.int32, shape=(None))\n",
    "    logits = cnn_model(inputs, training=False)\n",
    "    loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
    "    saver = tf.train.Saver()\n",
    "    sess.run([tf.global_variables_initializer()])\n",
    "    saver.restore(sess, \"./trained_model/model.ckpt\")\n",
    "    return inputs, labels, logits, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uniform_perturbation(sample, x_min, x_max, n=1, sigma=1, seed=0, image_size=28):\n",
    "    import torch\n",
    "    import torch.distributions as dist\n",
    "    sample = torch.tensor(sample).view(-1, image_size*image_size)\n",
    "    if isinstance(x_min, (int, float, complex)) and isinstance(x_max, (int, float, complex)):\n",
    "        prior = dist.Uniform(low=torch.max(sample-sigma, torch.tensor([x_min])), high=torch.min(sample+sigma, torch.tensor([x_max])))\n",
    "    elif isinstance(x_min, torch.Tensor) and isinstance(x_max, torch.Tensor):\n",
    "        prior = dist.Uniform(low=torch.max(sample-sigma, x_min), high=torch.min(sample+sigma, x_max))\n",
    "    else:\n",
    "        raise ValueError('Type of x_min and x_max {0} is not supported'.format(type(x_min)))\n",
    "    x = prior.sample(torch.Size([n])).view(-1, image_size, image_size)\n",
    "    return x.numpy(), prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_grey_scale_numpy_array(array):\n",
    "    import matplotlib.pyplot as plt\n",
    "    %matplotlib inline  \n",
    "    imgplot = plt.imshow(array, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_property_function(logits, labels):\n",
    "    equal_to_labels = logits.argmax(axis=1) == labels\n",
    "    correct_logits = np.array([logits[idx][label] for idx, label in enumerate(labels)]) \n",
    "    z_c = np.exp(correct_logits)/np.exp(logits).sum(axis=1)\n",
    "    logits_rankings = np.argsort(logits, axis=1)\n",
    "    best_logits_without_labels = np.array([logit[logits_ranking[-2]] if equal_to_label else logit[logits_ranking[-1]] \n",
    "                                           for logit, logits_ranking, equal_to_label in zip(logits, logits_rankings, equal_to_labels)])\n",
    "    z_i = np.exp(best_logits_without_labels)/np.exp(logits).sum(axis=1)\n",
    "    return z_i - z_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_s_xn(samples, input_labels):\n",
    "    tf.reset_default_graph()\n",
    "    with tf.Session() as sess:\n",
    "        inputs, labels, logits, loss = evaluation_model(get_default_hparams(), sess=sess)\n",
    "        loss_run_time, logits_run_time = sess.run([loss, logits], feed_dict={inputs: samples, labels: input_labels})\n",
    "        accuracy = 100 * np.sum(np.argmax(logits_run_time, axis=1) == perturbated_labels) / perturbated_labels.shape[0]\n",
    "        s_xn = compute_property_function(logits_run_time, perturbated_labels)\n",
    "    return s_xn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, sys\n",
    "from IPython.display import clear_output\n",
    "def update_progress(progress):\n",
    "    bar_length = 20\n",
    "    if isinstance(progress, int):\n",
    "        progress = float(progress)\n",
    "    if not isinstance(progress, float):\n",
    "        progress = 0\n",
    "    if progress < 0:\n",
    "        progress = 0\n",
    "    if progress >= 1:\n",
    "        progress = 1\n",
    "    block = int(round(bar_length * progress))\n",
    "    clear_output(wait = True)\n",
    "    text = \"Progress: [{0}] {1:.1f}%\".format( \"#\" * block + \"-\" * (bar_length - block), progress * 100)\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The bounds in NN-space\n",
    "x_min = (0-0.1307)/0.3081\n",
    "x_max = (1-0.1307)/0.3081"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./trained_model/model.ckpt\n",
      "Loss:0.025718383491039276, Accuracy:99.35%\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "with tf.Session() as sess:\n",
    "    logits, labels = evaluation(eval_x, eval_y, get_default_hparams(), sess=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_idx = random.randrange(0, eval_x.shape[0])\n",
    "sample_x, sample_y = eval_x[sample_idx], eval_y[sample_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAADa1JREFUeJzt3X+IHPUZx/HP09iAmPozJD2S1LRVpKKSlEPFxJpSLRoKZyDR5g9JaemJ6WELRRT/USiBUmyrQShc8WhCEpNIjImmtClaais1mISan5poOJNtQtIQUaN/aPTpHzcp13j73b3dmZ25e94vCLs7z87Mw+rnZna/s/s1dxeAeL5QdgMAykH4gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8EdV4nd2ZmXE4IFMzdrZnntXXkN7PbzexNM3vLzB5qZ1sAOstavbbfzCZIOiDpNkk1Sa9JWuzu+xLrcOQHCtaJI//1kt5y90Pu/rGktZJ62tgegA5qJ/zTJB0Z9riWLfs/ZtZrZtvNbHsb+wKQs3Y+8Bvp1OJzp/Xu3i+pX+K0H6iSdo78NUkzhj2eLuloe+0A6JR2wv+apCvN7KtmNlHS9yVtzqctAEVr+bTf3c+YWZ+kP0uaIGnA3ffm1hmAQrU81NfSznjPDxSuIxf5ABi7CD8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IqqNTdKPz7rnnnmR95cqVyXqjX3fu6UlPz/j8888n6ygPR34gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCKqtWXrNbFDSB5I+lXTG3bsbPJ9Zegtw66231q0988wzyXUvvPDCtvZ98ODBZH3NmjV1a6tWrUque+jQoZZ6iq7ZWXrzuMjn2+5+MoftAOggTvuBoNoNv0vaamY7zKw3j4YAdEa7p/1z3P2omU2R9Bcze8PdXx7+hOyPAn8YgIpp68jv7kez2xOSNkq6foTn9Lt7d6MPAwF0VsvhN7MLzOxLZ+9L+q6kPXk1BqBY7Zz2T5W00czObmeNu/8pl64AFK6tcf5R74xx/kIsWrSobm3t2rUd7GR0jhw5kqyvW7cuWX/wwQfzbGfcaHacn6E+ICjCDwRF+IGgCD8QFOEHgiL8QFD8dPc4cOONN5bdQktmzJiRrC9dujRZX79+fbK+Y8eOUfcUCUd+ICjCDwRF+IGgCD8QFOEHgiL8QFCEHwiKr/SOAVOmTEnWUz+fPWnSpOS6J0+mf3j5pZdeStYb/fz2wMBA3drkyZOT6zZSq9WS9U2bNtWt3X///W3tu8r4Si+AJMIPBEX4gaAIPxAU4QeCIvxAUIQfCIrv848BDzzwQLLeaCw/Zfny5cn6smXLWt62JPX09NStbdmyJbnuxRdfnKxPnz49Wb/22muT9eg48gNBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUA3H+c1sQNL3JJ1w92uyZZdKWidppqRBSXe5+7vFtTm+XXHFFcl6X19fhzrJ36uvvlq3Nn/+/OS6jX6Xv9E4f+r3Ai6//PLkuu+8806yPh40c+T/g6Tbz1n2kKQX3f1KSS9mjwGMIQ3D7+4vSzp1zuIeSSuy+ysk3ZlzXwAK1up7/qnufkySstv070wBqJzCr+03s15JvUXvB8DotHrkP25mXZKU3Z6o90R373f3bnfvbnFfAArQavg3S1qS3V8iqf7PpAKopIbhN7OnJf1T0lVmVjOzH0n6paTbzOygpNuyxwDGkIbv+d19cZ3Sd3LuJawJEyYk6xMnTuxQJ521bdu2ZP3uu+9O1l955ZVk/eqrr65bu/nmm5PrMs4PYNwi/EBQhB8IivADQRF+ICjCDwTFT3ejst54442yWxjXOPIDQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFCM81fAY489Vti2a7Vasv74448Xtm9UG0d+ICjCDwRF+IGgCD8QFOEHgiL8QFCEHwiKcf4OOP/885P1yy67rLB9L1++PFn/8MMPC9s3qo0jPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8E1XCc38wGJH1P0gl3vyZb9qikH0v6T/a0h939j0U1OdYtXLgwWb/hhhva2v6+ffvq1p577rm2tj2WHT58uG5t9+7dHeykmpo58v9B0u0jLP+tu8/K/hF8YIxpGH53f1nSqQ70AqCD2nnP32dmu8xswMwuya0jAB3Ravh/J+nrkmZJOibp1/WeaGa9ZrbdzLa3uC8ABWgp/O5+3N0/dffPJP1e0vWJ5/a7e7e7d7faJID8tRR+M+sa9nCBpD35tAOgU5oZ6nta0jxJk82sJukRSfPMbJYklzQo6d4CewRQgIbhd/fFIyx+qoBe0KK9e/fWrb399tsd7GR0Jk+enKz39/e3tf3BwcG6tddff72tbY8HXOEHBEX4gaAIPxAU4QeCIvxAUIQfCIqf7u6ATz75JFk/c+ZMsn7eeePzP9OcOXOS9Z6eng51EhNHfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IanwOIFfM2rVrk/X77rsvWZ87d26yftVVV9WtzZw5M7lu6muvRXviiScK3f7WrVsL3f5Yx5EfCIrwA0ERfiAowg8ERfiBoAg/EBThB4JinL8CDhw4kKw3Gue/7rrr6tYWLFiQXHfDhg3Jemqaa0m66aabkvWBgYG6ta6urrq1ZtRqtWR91apVbW1/vOPIDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBmbunn2A2Q9JKSV+W9Jmkfnd/wswulbRO0kxJg5Lucvd3G2wrvbOgUt/Hl6R9+/YVtu9GU1Xv2bMnWZ83b16yPm3atNG29D8fffRRsn7LLbck6zt37mx532OZu1szz2vmyH9G0s/d/RuSbpT0EzO7WtJDkl509yslvZg9BjBGNAy/ux9z953Z/Q8k7Zc0TVKPpBXZ01ZIurOoJgHkb1Tv+c1spqTZkrZJmurux6ShPxCSpuTdHIDiNH1tv5lNkrRB0s/c/X2zpt5WyMx6JfW21h6AojR15DezL2oo+Kvd/dls8XEz68rqXZJOjLSuu/e7e7e7d+fRMIB8NAy/DR3in5K0391/M6y0WdKS7P4SSZvybw9AUZoZ6psr6e+SdmtoqE+SHtbQ+/71kr4i6bCkRe5+qsG2GOobwdSpU5P1LVu2JOuzZ8/Os53K2LhxY7K+cOHCDnUytjQ71NfwPb+7/0NSvY19ZzRNAagOrvADgiL8QFCEHwiK8ANBEX4gKMIPBNVwnD/XnTHO35JGP3G9evXqurVZs2Yl173ooota6ikPa9asSdb7+vqS9ffeey/PdsaNPL/SC2AcIvxAUIQfCIrwA0ERfiAowg8ERfiBoBjnH+fuuOOOZH3p0qXJ+vz585P1J598MlnftWtX3dq6deuS654+fTpZx8gY5weQRPiBoAg/EBThB4Ii/EBQhB8IivADQTHOD4wzjPMDSCL8QFCEHwiK8ANBEX4gKMIPBEX4gaAaht/MZpjZX81sv5ntNbOfZssfNbN/m9m/sn/pL34DqJSGF/mYWZekLnffaWZfkrRD0p2S7pJ02t0fa3pnXOQDFK7Zi3zOa2JDxyQdy+5/YGb7JU1rrz0AZRvVe34zmylptqRt2aI+M9tlZgNmdkmddXrNbLuZbW+rUwC5avrafjObJOlvkpa5+7NmNlXSSUku6Rcaemvwwwbb4LQfKFizp/1Nhd/MvijpBUl/dvffjFCfKekFd7+mwXYIP1Cw3L7YY2Ym6SlJ+4cHP/sg8KwFkvaMtkkA5Wnm0/65kv4uabekz7LFD0taLGmWhk77ByXdm304mNoWR36gYLme9ueF8APF4/v8AJIIPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IivADQTX8Ac+cnZT0zrDHk7NlVVTV3qral0Rvrcqzt8ubfWJHv8//uZ2bbXf37tIaSKhqb1XtS6K3VpXVG6f9QFCEHwiq7PD3l7z/lKr2VtW+JHprVSm9lfqeH0B5yj7yAyhJKeE3s9vN7E0ze8vMHiqjh3rMbNDMdmczD5c6xVg2DdoJM9szbNmlZvYXMzuY3Y44TVpJvVVi5ubEzNKlvnZVm/G646f9ZjZB0gFJt0mqSXpN0mJ339fRRuows0FJ3e5e+piwmX1L0mlJK8/OhmRmv5J0yt1/mf3hvMTdH6xIb49qlDM3F9RbvZmlf6ASX7s8Z7zOQxlH/uslveXuh9z9Y0lrJfWU0EflufvLkk6ds7hH0ors/goN/c/TcXV6qwR3P+buO7P7H0g6O7N0qa9doq9SlBH+aZKODHtcU7Wm/HZJW81sh5n1lt3MCKaenRkpu51Scj/najhzcyedM7N0ZV67Vma8zlsZ4R9pNpEqDTnMcfdvSrpD0k+y01s053eSvq6hadyOSfp1mc1kM0tvkPQzd3+/zF6GG6GvUl63MsJfkzRj2OPpko6W0MeI3P1odntC0kYNvU2pkuNnJ0nNbk+U3M//uPtxd//U3T+T9HuV+NplM0tvkLTa3Z/NFpf+2o3UV1mvWxnhf03SlWb2VTObKOn7kjaX0MfnmNkF2QcxMrMLJH1X1Zt9eLOkJdn9JZI2ldjL/6nKzM31ZpZWya9d1Wa8LuUin2wo43FJEyQNuPuyjjcxAjP7moaO9tLQNx7XlNmbmT0taZ6GvvV1XNIjkp6TtF7SVyQdlrTI3Tv+wVud3uZplDM3F9RbvZmlt6nE1y7PGa9z6Ycr/ICYuMIPCIrwA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQ/wUUQg5QgWtxNAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_grey_scale_numpy_array(sample_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = 0.6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Naive MCMC</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [####################] 100.0%\n",
      "Run time: 4757.847185373306s | Average accuracy: 0.9749879000000001\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "tf.reset_default_graph()\n",
    "accuracy_list = []\n",
    "step = 0\n",
    "sample_size = 10000\n",
    "repeat = 10000\n",
    "with tf.Session() as sess:\n",
    "    inputs, labels, logits, loss = evaluation_model(get_default_hparams(), sess=sess)\n",
    "    for i in range(repeat):\n",
    "        perturbated_samples, _ = uniform_perturbation(sample_x, x_min, x_max, n=sample_size, sigma=sigma)\n",
    "        perturbated_labels = np.repeat(sample_y, sample_size)\n",
    "        loss_run_time, logits_run_time = sess.run([loss, logits], feed_dict={inputs: perturbated_samples, labels: perturbated_labels})\n",
    "        accuracy = 100 * np.sum(np.argmax(logits_run_time, axis=1) == perturbated_labels) / perturbated_labels.shape[0]\n",
    "        accuracy_list += [accuracy/100]\n",
    "        update_progress(i / repeat)\n",
    "    update_progress(1)\n",
    "end_time = time.time()\n",
    "run_time = end_time - start_time\n",
    "print(\"Run time: {0}s | Average accuracy: {1}\".format(run_time, np.array(accuracy_list).mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fd944ec14e0>]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAD8CAYAAABzTgP2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAHkZJREFUeJzt3X98XHWd7/HXJ5n8Ttq0SVr6k1BaKMWWFoKAItpayy8F7gNE2L2CrrXLKldZV9eyIKjYXVZ21SvXq1bQiwrIroK4/LAF7AX1IhIUSoFCS+kv29Kmv9L8TmY+9485Seekk0yak3bSzPv5eMyjc77ne858z5x03vP9nu/MmLsjIiLSLS/bDRARkeFFwSAiIiEKBhERCVEwiIhIiIJBRERCFAwiIhKiYBARkRAFg4iIhCgYREQkJJbtBgxGdXW119bWZrsZIiLHlBdeeKHB3Wsy1Tsmg6G2tpb6+vpsN0NE5JhiZpsGUk9DSSIiEqJgEBGREAWDiIiEKBhERCREwSAiIiEKBhERCVEwiIhIyDH5OQY5+vY2d9AZT/Diln2ccfwYqsqL+P36BnYeaOOxl3ew80A7N198CmfWju13P+7OYy/vIOHOh06beJRaLyKHw47F33yuq6vzbH/A7bkNu3n6jV185v0zKC7Iz2pbhkpTexd5BiUF+ZgZy595k39+bO2g9rXmK+dTVph8Xtzh1FtX0NoZP6Te1y+fw5VnTgmVdXQlyDPIzzPMjPauOEWxkfEci2STmb3g7nUZ6ykYDl9rR5xTbvl1z/LG2y/OWluGyq0Pr+GeZwf0ochDHF9VyqbdLQOuX1qYT0tHOCS+/KFZHDe6hLFlhVz5/Wf73PbRz5xLbVUZRbE8mjvijC4pGFSbAdq74vzH81v40sOvUFNRhLvT0NTBvKmVrHu7idrqUpacdyIfmjOBxtYufvGnrfxp814+9q5auhJOQ1M7J4+voKq8iHjCGV1SQEG+AWBmg26XyJGiYIho275WKksLKC08dLStdumjoeXVX17EqOLBv0AdTe5OS0ecWL7R0h7HgdNve6LP+v/97KmUFcb44gUzycs7+GLX1hlP21Nydz7wzWdYv7PpkHUb/vminn24Ozf/cg33Prc5+kEBP/3EWfxm7U7Ki2MsmDmOvc0dnD2tit+u28WSn7zQU2/hKeN58rW3h+Qx0zFL9pAA5kwezbiKYs46YSwTKouZN3UME0cXs7u5g/uf28y7pldx2uRKuhJOUSzvkDBp7YiTcGfdziaqygoZXVqQtb+zts44OxvbeXHrPtb8ZT87G9v485Z9TKsu46xpVbzzhLGMLing+bf28IPfbuCGhScxd0ol8YSzr7WTHfvbaGztJJZv/GVvK3taOti+r429LR0caOuitrqUUcUFrN66n8ljSpg+rpyK4gIOtHUCEHcnkXDKimIkHDY2NDO2rJCaiiIK8o3JY0pp7Yiz80A7M4+r4NSJoxg3qjgrz1V/ul9vs/XGQcEwSN3vGs9c9iRwaG+gsa2TOV9eGSr71kfmctm8SUekPYPV1hnnI8v/wEtb9vE/Fkznzt+sz7jNd/7qdC6afRzPvrmbaTXlHDf66PzHenT1dj593596lpdeOJPr3ntiqM7+1k6WP/Mm31n15pA97qTKEr58yanMP7mGroRTXJDPpt3NbNmTfFOQZ8ZF3/5tT/2LZh/HlLGl5JtRXV7E42u2s+tAOx89p5Zfr9nO7qYOzp1RzY8H2fMCOHd6Nb9b30BBvtEZP/T/Zp5BwulZ/6n3nciM8eXsa+lk854WDGPznmaKYvnJtubBxt0tnHn8GE6oKaeiOEYi4bR1Jpg7tZKW9i7MjDGlBext6aSsKJ/Ne1p4+MVttLR38dxbe4jlG2/taqa549ChwMEqiuXRGU+QCA6xtqqUjUGvc3RJAftbO3vqxvKMvDzDgPauBGaQZ0Y80f9rV1Esj5qKIlo74uTnGVXlRWxsaKasKIa70xFPcKCti+ryIk6fWklVeSGVpYW8tGUfXXGnuqKQPc0dHD+2jOqKQrbvb2NsaTKMmtq7+MOG3eTnGSUF+YwqSYZ2aVE+XXEn4c62fa3sbekknnCa27vY0NBMR1eCkoJ8SgvzqSovZFxFMTPGl9PWGae2qozJY0rpSiQYV1HMjsZWWjriNLV1kZ9nNLZ2Ul4c49p31Q56aFXBcJiW/mI1zR1x/uulbaHy3sFw51Pr+Pcn3gDg3z98Gv/wny+lrZdNV37vWf64cc+A6582eTQPX3/uEWzRkePurN/ZxKJvPUNxLJ/vf/QMfr++gRWv7GBsWSF/2ryPH1xTx4xx5XTGE0weU0pJ4dG5XuHubN3bysbdzazf2cRX/utVAK5774m0dcZ5u7GNx9fsCG0zqjhGY1sXF77jOCpLC9nZ2EZHPEFNeRErX32bE2vKeHNXM2fWjmHV67vSPm5VWSG7mzsit797yG90SQFn1o7l7GljmTG+gnedWEUs6Plt3dvKWw3NxN3Z09TB3pYOzjuphle27acr7pgZ8USCsWVF7G/tZN7USiZVllBckE9XPEFze5zRpcleUDzh7G5qZ9yoYlo6uognnIpePaTWoLfbHQruyTdB63c1UVKQT3tXnH0tnazdcYBXtzXS3pVgVEmMdW83sWVvC/G4s3DWeIoL8tjX0knCnYTDpt3NyV5NWxcAp02ppKmtk7/sayXhyetevc0YV055cYzOIGAaWztp7ohTEFwbq6kooqqskDwzigqSE0DHjyqmvChGe1ecPc0dbNrdwoZdzeTlQVvnoY+RzmOfeQ+zJo4a1DlVMBym3sND3Xq/4N//x83c+ODL/OjjZ1J3/Bhm9+o9vP61Cwad5q9s28+sCaP67Wa2d8VxJ+0wTjzhnPhPj6Xd7sYLZ/K+k8dRXJDH1LGlGgMfhhIJDw3XDcT6nQdoaOqgOng3PHvyaMaPKqatM/kCWVKQ3zNcs2VvCzv2t9HS0UVenpH6X//ZN3czd0olZtDQ1MEVZ0xi3pQxh92eY10i4ZgdOtSzu6mdsWWFHGjvYl9zJ1XlhZQVDc2kTvdkgO5uauftxnb2tXbQ1hlnUmUpFcUxyotjuCd7QHtbOhhXUUz+IM/LQIMh0pGZ2W3ApUAC2Al8zN23pak3FbgLmAI4cJG7bzSzBcC/AYXAC8An3L0rSpsGoys+sKQG2LG/DbNklz+W5uScfPOvWfOV8ykP/mgSCednz2/hv82blPad6vMb9/Dh74Uvtp47vZqfLj6LjQ3NHGjrojCWx2vbG7nhgRd76vQOrCdefZtP/vhgWP74b97JeSdl/Np1GUYG8yI8fVwF08d13y/vKS8uyOe40cm/t+535LMnj+5zP5+eP/2wH3sk6uscVJUXATCqeOiv83SHUFV5Uc/j9GXC6JIhfey+ROoxmNkod28M7n8GmOXu16Wp93+BZe7+hJmVkwySNmAT8H53f8PMvgpscve7Mz3uUPcYFt9T3+cFybf+5SL2tXSyoaGJM44fy40PruaJV3dSf/NCIPnCP62Pd+kbb7+YT/yf53lq7U4AqsuLuO+TZ3HS+Aog2QWe+aVfp902irf+5SL1CETkEAPtMUT65HN3KATKSPYGejdkFhBz9yeCbZrcvQWoAtrd/Y2g6hPA5VHaM1j9zVJp6Ygz77YnuPy7z/LD373F9v1tjB91MNXz8oxPz09eKD3j+DGhbTu6Ej2hANDQ1M6ibz7Dz/64mdqlj4ZC4dpzjufDZ0xm9qS+39UNxK9veI9CQUQiiTxIZmbLgGuA/cD8NFVOAvaZ2YPACcCTwFKgASgwszp3rweuIDnUNCycOnEUr2xr5LGXt/eUffWR5MXD988cF6r7hfNn8vlFJ2NmfOmXa/jJH5KzUk66+fG0+1764Muh5VWffx8nVJcByV7EO25dQVdwca3+5oUse/Q1nnztbZ6/aSHFBfk0NLUzqriARd98mpaOOFPHlrL0wpnUZfjUsYjIQGQcSjKzJ4Hj0qy6yd0fTql3I1Ds7rf22v4K4G5gHrAZeAB4zN3vNrNzgK8DRcBK4GJ3n9dHO5YASwCmTp16xqZNg58S2Ns/PfQy96XMp1972wV8+Vev8LPnt3DLB2f1BEK3wlgeb3ztwj7399KWfVz6nd/3LF8/fzqf+8BJPL9xDx9Z/odQ3af+4b2cWFPeexciIkNuyIaS3H2hu78jze3hXlXvI/1Q0Fbgz+6+Ibiw/Evg9GDfz7r7e9z9ncAzwLp+2rHc3evcva6mZmgvqhbF8qgoPth5Ki7I51PvS16M6x0KAIX5/T9tp02pDC1fv2A6eXnGWdOqesr+9rxprFt2oUJBRIadqLOSZrh794v5JUC6L9Z5HhhjZjXuvgtYANQH249z951mVgR8EVgWpT2D1d6VoCiWz4K545gXvKhXVxSG6tywcAanThzNDT/7M8/euCDjPt/42oU0t3cxpiy8n+H0eQcRkXSiXmO43cxOJjnLaBNwHYCZ1QHXuftid4+b2eeBpyx5VfQF4AfB9l8wsw+S7Ll8191/E7E9g9LemaAolsf/vOrgKFbvr8I4e1oVZ0+r4pWvXjCgfRbG8iiMFWauKCIyzEQKBndPO4souJi8OGX5CWBOmnpfAL4QpQ2HY81f9vPBO3/HvYvP4t3Tq3vKk9/eeejw0KJZ41n5anLG0lkn6MKuiOSGnPo9hj9s2A0kp6emBkNHV4LCNMGw/Jo6fvDMBk6d1P+nkUVERpKcCoa+XtzbuxIU9fGbCp88b9qRbJKIyLCTU8HQl6ffSP9lZCIiuSgnf/P5GPzeQBGRoyangiHdQFKm73QXEck1ORUM3TpTvk21+4K0iIgk5VQwvPH2AYDQz0lu3jPw3yoWEckFORUMDU0Hf9Vq7Y7kF8N2fyXFzRefkpU2iYgMNzkVDKm/wXHBt37LzgNtJIIr0bMmDO6n8kRERpqcCobeH2Nobo/3XG9I9wE3EZFclFOvhtZrXlKeJcMBoCDDN6aKiOSKnHo17N1jyDPjup++AEAsX195ISICOR4Mqcubd2t2kogI5Fow9BpKWnxPfc/9d0T8rWURkZEit4KhV49h7Y4DPfcnjyk5yq0RERmeciwY+r6OoK/VFhFJyq1g6KN8WnXZUW2HiMhwllvB0EcybGhoProNEREZxnIqGKZVl6ct/85fnX6UWyIiMnzlVDCcMqEibfmWvZqqKiLSLaeCIa+PsaT3zKhOWy4ikotyKhhaO+Npy/V1GCIiB+XUK+ItD69JWx7L01RVEZFuORUMe1s605arxyAiclCkV0Qzu83MVpvZi2a20swmpqkzP1jffWszs8uCdSeY2XNmts7MHjCzwijtGSx9gZ6IyEFR3yrf4e5z3H0u8AhwS+8K7r7K3ecGdRYALcDKYPW/At909xnAXuATEdszKPkaShIR6REpGNy9MWWxDPAMm1wBPO7uLZb8DooFwM+DdfcAl0Vpz2AV5GkoSUSkWyzqDsxsGXANsB+Yn6H6VcA3gvtVwD537wqWtwKTorZnMDSUJCJyUMa3ymb2pJmtSXO7FMDdb3L3KcC9wPX97GcCMBtY0V2UplqfPQ4zW2Jm9WZWv2vXrkzNPiwx9RhERHpk7DG4+8IB7us+4FHg1j7WXwk85O7dU4MagEoziwW9hsnAtn7asRxYDlBXV5dpyOqw6PeeRUQOijoraUbK4iXA2n6qXw3c373g7g6sInndAeBa4OEo7RksXXwWETko6lvl24NhpdXAIuCzAGZWZ2Z3dVcys1pgCvB0r+2/CHzOzNaTvOZwd8T2HDZ9HYaISFiki8/ufnkf5fXA4pTljaS5sOzuG4B3RmlDFBtvvzhbDy0iMmxpcF1EREIUDCIiEpKzwXDKhFHZboKIyLCUs8HwtctOzXYTRESGpZwNhpOPU49BRCSdnA0GfXRBRCS9HA4GJYOISDo5GwwiIpJezgaDOgwiIunlbjCk/XJXERHJ3WBQLoiIpJWzwSAiIunlbDDENF9VRCStnA0G01iSiEhaORsMIiKSnoJBRERCFAwiIhKiYBARkRAFg4iIhORUMFxZNznbTRARGfZyKhgmVpZkuwkiIsNeTgWDiIhkpmAQEZEQBYOIiITkVDC4Z7sFIiLDX6RgMLPbzGy1mb1oZivNbGKaOvOD9d23NjO7LFh3vZmtNzM3s+oobRERkaERtcdwh7vPcfe5wCPALb0ruPsqd58b1FkAtAArg9W/BxYCmyK2Q0REhkgsysbu3piyWAZkGqy5Anjc3VuC7f8M+qZTEZHhJFIwAJjZMuAaYD8wP0P1q4BvDPJxlgBLAKZOnTqYXWRMLRERGcBQkpk9aWZr0twuBXD3m9x9CnAvcH0/+5kAzAZWDKah7r7c3evcva6mpmYwu+jx/5YuiLS9iMhIlrHH4O4LB7iv+4BHgVv7WH8l8JC7dw5wf0eMPgEtItK3qLOSZqQsXgKs7af61cD9UR5PRESOvKizkm4PhpVWA4uAzwKYWZ2Z3dVdycxqgSnA06kbm9lnzGwrMBlYnbrNEaEPMoiIZBR1VtLlfZTXA4tTljcCk9LU+zbw7ShtOFyaACUi0r+c+uSziIhkpmAQEZGQnAoGXWEQEcksp4IBQJcYRET6l1PB8KPfbyShboOISL9yKhia2ruy3QQRkWEvp4JBREQyUzCIiEiIgkFEREIUDCIiEqJgEBGREAWDiIiEKBhERCREwSAiIiEKBhERCVEwiIhIiIJBRERCFAwiIhKiYBARkRAFg4iIhCgYREQkRMEgIiIhCgYREQlRMIiISEikYDCz28xstZm9aGYrzWximjrzg/XdtzYzuyxYd6+ZvW5ma8zsh2ZWEKU9IiISXdQewx3uPsfd5wKPALf0ruDuq9x9blBnAdACrAxW3wvMBGYDJcDiiO0REZGIYlE2dvfGlMUywDNscgXwuLu3BNs/1r3CzP4ITI7SHhERiS5SMACY2TLgGmA/MD9D9auAb6TZRwHwUeCzUdsjIiLRZBxKMrMng2sAvW+XArj7Te4+heSw0PX97GcCySGjFWlW/2/gGXf/bT/bLzGzejOr37VrV6Zmi4jIIGXsMbj7wgHu6z7gUeDWPtZfCTzk7p2phWZ2K1AD/G2GdiwHlgPU1dVlGrISEZFBijoraUbK4iXA2n6qXw3c32v7xcD5wNXunojSFhERGRpRZyXdHgwrrQYWEVwjMLM6M7uru5KZ1QJTgKd7bf89YDzwbDCV9ZBZTSIicnRFnZV0eR/l9aRMPXX3jcCkNPUiX/wWEZGhpU8+i4hIiIJBRERCFAwiIhKiYBARkRAFg4iIhCgYREQkRMEgIiIhCgYREQlRMIiISIiCQUREQhQMIiISomAQEZEQBYOIiIQoGEREJETBICIiIQoGEREJUTCIiEiIgkFEREIUDCIiEqJgEBGREAWDiIiEKBhERCREwSAiIiEKBhERCYkUDGZ2m5mtNrMXzWylmU1MU2d+sL771mZmlwXr7jazl4J9/NzMyqO0R0REoovaY7jD3ee4+1zgEeCW3hXcfZW7zw3qLABagJXB6r9399PcfQ6wGbg+YntERCSiSMHg7o0pi2WAZ9jkCuBxd29J3d7MDCgZwPYiInKERb7GYGbLzGwL8Nek6TH0chVwf6/tfwTsAGYCd0Ztj4iIRJMxGMzsSTNbk+Z2KYC73+TuU4B76WcoyMwmALOBFanl7v5xYCLwGvCRfrZfYmb1Zla/a9euAR2ciIgcvozB4O4L3f0daW4P96p6H3B5P7u6EnjI3TvTPEYceKC/7d19ubvXuXtdTU1NpmaLiMggRZ2VNCNl8RJgbT/VryZlGMmSpnffBz6UYXsRETkKYhG3v93MTgYSwCbgOgAzqwOuc/fFwXItMAV4OmVbA+4xs1HB/ZeAv4vYHhERiShSMLh72qEfd68HFqcsbwQm9aqTAN4d5fFFRGTo6ZPPIiISomAQEZEQBYOIiIQoGEREJETBICIiIQoGEREJUTCIiEiIgkFEREIUDCIiEqJgEBGREAWDiIiEKBhERCREwSAiIiEKBhERCYn6ewzHlPNOqmHrnpZsN0NEZFjLqR5DQZ5RWpSf7WaIiAxrORUMIiKSmYJBRERCFAwiIhKiYBARkRAFg4iIhCgYREQkJKeCwbPdABGRY0BOBQOAYdlugojIsJZzwSAiIv2LFAxmdpuZrTazF81spZlNTFNnfrC++9ZmZpf1qnOnmTVFaYuIiAyNqD2GO9x9jrvPBR4Bbuldwd1XufvcoM4CoAVY2b3ezOqAyojtEBGRIRIpGNy9MWWxjMzXd68AHnf3FgAzywfuAP4xSjtERGToRP52VTNbBlwD7AfmZ6h+FfCNlOXrgV+5+3az/i8Km9kSYAnA1KlTB91eERHpX8Yeg5k9aWZr0twuBXD3m9x9CnAvyRf6vvYzAZgNrAiWJwIfBu4cSEPdfbm717l7XU1NzUA2ERGRQcjYY3D3hQPc133Ao8Ctfay/EnjI3TuD5XnAdGB90FsoNbP17j59gI8nIiJHQNRZSTNSFi8B1vZT/Wrg/u4Fd3/U3Y9z91p3rwVaFAoiItkXdVbS7cGw0mpgEfBZSM40MrO7uiuZWS0wBXg64uOJiMgRFunis7tf3kd5PbA4ZXkjMCnDvsqjtEVERIaGPvksIiIhCgYREQnJqWBw1/eriohkklPBAJDhc3QiIjkv54JBRET6p2AQEZEQBYOIiIQoGEREJETBICIiIQoGEREJUTCIiEiIgkFEREIUDCIiEqJgEBGREAWDiIiEKBhERCQk0g/1HGvqasdyoK0r280QERnWcioYPj1fPyktIpKJhpJERCREwSAiIiEKBhERCVEwiIhIiIJBRERCFAwiIhKiYBARkRAFg4iIhJi7Z7sNh83MdgGbBrl5NdAwhM05FuiYc4OOeeSLerzHu3tNpkrHZDBEYWb17l6X7XYcTTrm3KBjHvmO1vFqKElEREIUDCIiEpKLwbA82w3IAh1zbtAxj3xH5Xhz7hqDiIj0Lxd7DCIi0o+cCgYzu8DMXjez9Wa2NNvtGSwzm2Jmq8zsNTN7xcw+G5SPNbMnzGxd8O+YoNzM7NvBca82s9NT9nVtUH+dmV2brWMaKDPLN7M/m9kjwfIJZvZc0P4HzKwwKC8KltcH62tT9nFjUP66mZ2fnSMZGDOrNLOfm9na4HyfM9LPs5n9ffB3vcbM7jez4pF2ns3sh2a208zWpJQN2Xk1szPM7OVgm2+bmR1WA909J25APvAmMA0oBF4CZmW7XYM8lgnA6cH9CuANYBbwdWBpUL4U+Nfg/kXA44ABZwPPBeVjgQ3Bv2OC+2OyfXwZjv1zwH3AI8HyfwBXBfe/B/xdcP9TwPeC+1cBDwT3ZwXnvgg4IfibyM/2cfVzvPcAi4P7hUDlSD7PwCTgLaAk5fx+bKSdZ+A84HRgTUrZkJ1X4I/AOcE2jwMXHlb7sv0EHcUTcQ6wImX5RuDGbLdriI7tYeADwOvAhKBsAvB6cP/7wNUp9V8P1l8NfD+lPFRvuN2AycBTwALgkeCPvgGI9T7HwArgnOB+LKhnvc97ar3hdgNGBS+S1qt8xJ7nIBi2BC92seA8nz8SzzNQ2ysYhuS8BuvWppSH6g3klktDSd1/cN22BmXHtKDrPA94Dhjv7tsBgn/HBdX6OvZj7Tn5FvCPQCJYrgL2uXv3D3mntr/n2IL1+4P6x9IxTwN2AT8Khs/uMrMyRvB5dve/AP8GbAa2kzxvLzCyz3O3oTqvk4L7vcsHLJeCId0Y2zE9JcvMyoFfADe4e2N/VdOUeT/lw46ZfRDY6e4vpBanqeoZ1h0zx0zyHfDpwHfdfR7QTHKIoS/H/DEH4+qXkhz+mQiUARemqTqSznMmh3uMkY89l4JhKzAlZXkysC1LbYnMzApIhsK97v5gUPy2mU0I1k8AdgblfR37sfScvBu4xMw2Aj8jOZz0LaDSzGJBndT29xxbsH40sIdj65i3Alvd/blg+eckg2Ikn+eFwFvuvsvdO4EHgXcxss9zt6E6r1uD+73LByyXguF5YEYwu6GQ5IWqX2W5TYMSzDC4G3jN3b+RsupXQPfMhGtJXnvoLr8mmN1wNrA/6KquABaZ2ZjgndqioGzYcfcb3X2yu9eSPHe/cfe/BlYBVwTVeh9z93NxRVDfg/KrgtksJwAzSF6oG3bcfQewxcxODoreD7zKCD7PJIeQzjaz0uDvvPuYR+x5TjEk5zVYd8DMzg6ew2tS9jUw2b4Ac5Qv9lxEcgbPm8BN2W5PhOM4l2TXcDXwYnC7iOTY6lPAuuDfsUF9A74THPfLQF3Kvv4GWB/cPp7tYxvg8b+Pg7OSppH8D78e+E+gKCgvDpbXB+unpWx/U/BcvM5hztbIwrHOBeqDc/1LkrNPRvR5Br4CrAXWAD8hObNoRJ1n4H6S11A6Sb7D/8RQnlegLnj+3gT+F70mMGS66ZPPIiISkktDSSIiMgAKBhERCVEwiIhIiIJBRERCFAwiIhKiYBARkRAFg4iIhCgYREQk5P8DBy5raRUeaFIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#sigma = 0.5 \n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "error_list = (1 - np.array(accuracy_list))\n",
    "log_i_history = [np.log(error_list[:i].mean()) for i in range(1, len(error_list))]\n",
    "plt.plot(range(len(log_i_history)), log_i_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Adaptive Multi-level Splitting</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mh_update(samples, sample_labels, width_proposal, l_k, inputs, labels, \n",
    "              width_inc=1.02, width_dec=0.5, update_steps=250, sess=tf.Session()):\n",
    "    #Take reference to the original code from the paper, which provides a efficient method for MH process\n",
    "    import torch\n",
    "    import torch.distributions as dist\n",
    "    sample_size = samples.shape[0]\n",
    "    x = torch.tensor(samples).view(-1, 28*28)\n",
    "    acc_ratio = torch.zeros(sample_size)\n",
    "    for i in range(update_steps):\n",
    "        g_bottom = dist.Uniform(low=torch.max(x - width_proposal.unsqueeze(-1), prior.low), high=torch.min(x + width_proposal.unsqueeze(-1), prior.high))\n",
    "        x_new = g_bottom.sample()\n",
    "        loss_run_time, logits_run_time = sess.run([loss, logits], feed_dict={inputs: x_new.view(-1, 28, 28).numpy(), \n",
    "                                                                             labels: sample_labels})\n",
    "        s_xn = compute_property_function(logits_run_time, sample_labels)\n",
    "        \n",
    "        g_top = dist.Uniform(low=torch.max(x_new - width_proposal.unsqueeze(-1), prior.low), high=torch.min(x_new + width_proposal.unsqueeze(-1), prior.high))\n",
    "        lg_alpha = (prior.log_prob(x_new) - prior.log_prob(x)+ g_top.log_prob(x) - g_bottom.log_prob(x_new)).sum(dim=1)\n",
    "        acceptance = torch.min(lg_alpha, torch.zeros_like(lg_alpha))\n",
    "        \n",
    "        log_u = torch.log(torch.rand_like(acceptance))\n",
    "        acc_idx = torch.tensor((log_u <= acceptance).numpy() & (s_xn >= l_k))\n",
    "        acc_ratio += acc_idx.float()\n",
    "        x = torch.where(acc_idx.unsqueeze(-1), x_new, x)\n",
    "    if not all(s_x >= l_k for s_x in s_xn):\n",
    "        print(acc_idx)\n",
    "        print(s_xn)\n",
    "        raise ValueError(\"Bug!\")\n",
    "    width_proposal = torch.where(acc_ratio > 0.124, width_proposal*width_inc, width_proposal)\n",
    "    width_proposal = torch.where(acc_ratio < 0.124, width_proposal*width_dec, width_proposal)  \n",
    "    return x.view(-1, 28, 28), width_proposal\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 100\n",
    "perturbated_samples, prior = uniform_perturbation(sample_x, x_min, x_max, n=sample_size, sigma=sigma)\n",
    "perturbated_labels = np.repeat(sample_y, sample_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_grey_scale_numpy_array(perturbated_samples[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantile = 0.1\n",
    "log_p_min = -250\n",
    "l_k = float('-inf')\n",
    "l_prev = float('-inf')\n",
    "log_i = 0\n",
    "k = 0\n",
    "width_proposal = sigma*torch.ones(sample_size)/30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width_proposal = sigma*torch.ones(sample_size)/30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "log_i_record = []\n",
    "step = 0\n",
    "with tf.Session() as sess:\n",
    "    inputs, labels, logits, loss = evaluation_model(get_default_hparams(), sess=sess)\n",
    "    while l_k < 0:\n",
    "        loss_run_time, logits_run_time = sess.run([loss, logits], feed_dict={inputs: perturbated_samples, labels: perturbated_labels})\n",
    "        accuracy = 100 * np.sum(np.argmax(logits_run_time, axis=1) == perturbated_labels) / perturbated_labels.shape[0]\n",
    "        s_xn = compute_property_function(logits_run_time, perturbated_labels)\n",
    "        \n",
    "        l_k = min(0, np.quantile(s_xn, quantile, interpolation='lower'))\n",
    "        p_k = np.where(s_xn>= l_k)[0].shape[0] / sample_size\n",
    "        log_i += math.log(p_k)\n",
    "        if log_i < log_p_min:\n",
    "            break\n",
    "        s_xn = s_xn[s_xn>=l_k]\n",
    "        resample_idx = np.random.choice(s_xn.shape[0], sample_size)\n",
    "        perturbated_samples = perturbated_samples[resample_idx]\n",
    "        s_xn = s_xn[resample_idx]\n",
    "        if not all(s_x >= l_k for s_x in s_xn):\n",
    "            raise ValueError(\"Bug Ar!\")\n",
    "        #perturbated_samples, width_proposal = mh_update(perturbated_samples, perturbated_labels, width_proposal, l_k, sess=sess, inputs=inputs, labels=labels)\n",
    "        #print(\"Loss:{}, Accuracy:{}%\".format(loss_run_time, accuracy))\n",
    "        #print(\"log_i: {0} | l_k: {1}\".format(log_i, l_k))\n",
    "        step += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loss:{}, Accuracy:{}%\".format(loss_run_time, accuracy))\n",
    "print(\"log_i: {0} | l_k: {1}\".format(log_i, l_k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Below are Testing </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######NAIVE MCMC##########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all(s_x > l_k for s_x in s_xn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.distributions as dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = perturbated_samples\n",
    "sample_labels = perturbated_labels\n",
    "width_inc=1.02\n",
    "width_dec=0.5\n",
    "update_steps=250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = samples.shape[0]\n",
    "x = torch.tensor(samples).view(-1, 28*28)\n",
    "acc_ratio = torch.zeros(sample_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "with tf.Session() as sess:\n",
    "    inputs, labels, logits, loss = evaluation_model(get_default_hparams(), sess=sess)\n",
    "    loss_run_time, logits_run_time = sess.run([loss, logits], feed_dict={inputs: perturbated_samples, labels: perturbated_labels})\n",
    "    accuracy = 100 * np.sum(np.argmax(logits_run_time, axis=1) == perturbated_labels) / perturbated_labels.shape[0]\n",
    "    s_xn = compute_property_function(logits_run_time, perturbated_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "with tf.Session() as sess:\n",
    "    inputs, labels, logits, loss = evaluation_model(get_default_hparams(), sess=sess)\n",
    "    g_bottom = dist.Uniform(low=torch.max(x - width_proposal.unsqueeze(-1), prior.low), high=torch.min(x + width_proposal.unsqueeze(-1), prior.high))\n",
    "    x_new = g_bottom.sample()\n",
    "    loss_run_time, logits_run_time = sess.run([loss, logits], feed_dict={inputs: x_new.view(-1, 28, 28).numpy(), \n",
    "                                                                         labels: sample_labels})\n",
    "    s_xn = compute_property_function(logits_run_time, sample_labels)\n",
    "\n",
    "    g_top = dist.Uniform(low=torch.max(x_new - width_proposal.unsqueeze(-1), prior.low), high=torch.min(x_new + width_proposal.unsqueeze(-1), prior.high))\n",
    "    lg_alpha = (prior.log_prob(x_new) - prior.log_prob(x)+ g_top.log_prob(x) - g_bottom.log_prob(x_new)).sum(dim=1)\n",
    "    acceptance = torch.min(lg_alpha, torch.zeros_like(lg_alpha))\n",
    "\n",
    "    log_u = torch.log(torch.rand_like(acceptance))\n",
    "    acc_idx = torch.tensor((log_u <= acceptance).numpy() & (s_xn >= l_k))\n",
    "    acc_ratio += acc_idx.float()\n",
    "    x = torch.where(acc_idx.unsqueeze(-1), x_new, x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_s_xn(perturbated_samples, perturbated_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if not all(s_x >= l_k for s_x in s_xn):\n",
    "    print(acc_idx)\n",
    "    print(s_xn)\n",
    "    raise ValueError(\"Bug!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Below are Testing </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_quantile = 0.1\n",
    "termination_threshold = math.exp(-250)\n",
    "MH_steps = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_perturbation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_perturbation(inputs, mean=0, stddev=0.3, seed=0):\n",
    "    perturbation = tf.random.normal(shape,mean=0.0,stddev=1.0,dtype=tf.dtypes.float32,seed=None,name=\"pertubation\")\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_perturbation(data, mean=0, sd=0.3):\n",
    "    perturbation = np.random.normal(loc=mean, scale=sd, size=data.shape)\n",
    "    return data+perturbation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_perturbation(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proposal(x_prior=0):\n",
    "    return scipy.stats.norm(x_prior,1).rvs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def real_density(x):\n",
    "    if x > 1 or x < 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proposal_ratio(x, x_prior):\n",
    "    x_prior_against_x = scipy.stats.norm(x,1).pdf(x_prior)\n",
    "    x_against_x_prior = scipy.stats.norm(x_prior,1).pdf(x)\n",
    "    return x_prior_against_x/x_against_x_prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def real_density_ratio(x, x_prior):\n",
    "    if x_prior < 0 or x_prior > 1:\n",
    "        return 1e10\n",
    "    else:\n",
    "        return real_density(x)/real_density(x_prior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = 100000\n",
    "x = proposal(3)\n",
    "result = []\n",
    "for i in range(M):\n",
    "    result += [x]\n",
    "    x_new = proposal(x)\n",
    "    alpha = min(1, proposal_ratio(x_new, x)*real_density_ratio(x_new, x))\n",
    "    u = random.random()\n",
    "    if u < alpha:\n",
    "        x = x_new\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "plt.hist(result[10000:], bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (flo)",
   "language": "python",
   "name": "florence"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
