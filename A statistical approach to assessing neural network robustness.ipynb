{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\"\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "((train_x, train_y),(eval_x, eval_y)) = tf.keras.datasets.mnist.load_data()\n",
    "train_x = train_x/np.float32(255)\n",
    "eval_x = eval_x/np.float32(255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HParams(object):\n",
    "    def __init__(self, **kwargs):\n",
    "        self.dict_ = kwargs\n",
    "        self.__dict__.update(self.dict_)\n",
    "\n",
    "    def update_config(self, in_string):\n",
    "        pairs = in_string.split(\",\")\n",
    "        pairs = [pair.split(\"=\") for pair in pairs]\n",
    "        for key, val in pairs:\n",
    "            self.dict_[key] = type(self.dict_[key])(val)\n",
    "        self.__dict__.update(self.dict_)\n",
    "        return self\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        return self.dict_[key]\n",
    "\n",
    "    def __setitem__(self, key, val):\n",
    "        self.dict_[key] = val\n",
    "        self.__dict__.update(self.dict_)\n",
    "\n",
    "\n",
    "def get_default_hparams():\n",
    "    return HParams(\n",
    "        image_dim = 28,\n",
    "        epoch_num = 50,\n",
    "        batch_size = 1000,\n",
    "        learning_rate = 1e-3,\n",
    "        next_batch = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bottleneck_block_resnet164(inputs, input_filters=64, training=True, scope='bottleneck_block_resetnet164'):\n",
    "    n_in = inputs.get_shape()[-1]\n",
    "    with tf.variable_scope(scope):\n",
    "        residual = inputs\n",
    "        h = tf.keras.layers.BatchNormalization(h, training=True, scope=\"bn_1\")\n",
    "        h = tf.nn.relu(h)\n",
    "        h = tf.layers.conv2d(inputs=inputs, filters=input_filters, kernel_size=[1,1], padding=\"same\", scope=\"conv1\")\n",
    "        \n",
    "        h = tf.keras.layers.BatchNormalization(h, training=True, scope=\"bn_2\")\n",
    "        h = tf.nn.relu(h)\n",
    "        h = tf.layers.conv2d(inputs=h, filters=input_filters, kernel_size=[3,3], padding=\"same\", scope=\"conv2\")\n",
    "        \n",
    "        h = tf.keras.layers.BatchNormalization(h, training=True, scope=\"bn_3\")\n",
    "        h = tf.layers.conv2d(inputs=h, filters=input_filters*4, kernel_size=[1,1], padding=\"same\", scope=\"conv3\")\n",
    "        \n",
    "        if n_in != inputs_filters*4:\n",
    "            shortcut = tf.layers.conv2d(inputs=inputs, filters=inputs_filters*4, kernel_size=[1,1], scope=\"conv4\")\n",
    "        else:\n",
    "            shortcut = inputs\n",
    "        return tf.nn.relu(shortcut + h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_pool(inputs, filters=32, kernel_size=[5,5], pool_size=[2,2]):\n",
    "    conv = tf.layers.conv2d(\n",
    "        inputs=inputs,\n",
    "        filters=filters,\n",
    "        kernel_size=kernel_size,\n",
    "        padding=\"same\",\n",
    "        activation=tf.nn.relu)\n",
    "    pool = tf.layers.max_pooling2d(inputs=conv, pool_size=pool_size, strides=2)\n",
    "    return pool\n",
    "\n",
    "def dense_layer(inputs, reshape=(7,7,64), units=1024, drop_out=True, drop_out_rate=0.4, training=True):\n",
    "    inputs = tf.reshape(inputs, [-1, reshape[0]*reshape[1]*reshape[2]])\n",
    "    dense = tf.layers.dense(inputs=inputs, units=units, activation=tf.nn.relu)\n",
    "    dropout = tf.layers.dropout(inputs=dense, rate=drop_out_rate, training=training)\n",
    "    return dropout\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model(inputs, training=True):\n",
    "    with tf.variable_scope(\"cnn_model\", reuse=tf.AUTO_REUSE):\n",
    "        inputs = tf.expand_dims(inputs, 3)\n",
    "        conv1 = conv_pool(inputs)\n",
    "        conv2 = conv_pool(conv1, filters=64)\n",
    "        dense = dense_layer(conv2, training=training)\n",
    "        logits = tf.layers.dense(inputs=dense, units=10)\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(data, batch_num, batch_size=100):\n",
    "    if batch_size == 0:\n",
    "        raise ValueError(\"batch_size cannot be zero\")\n",
    "    elif batch_num < 0:\n",
    "        raise ValueError(\"batch_num must be larger than or equal to zero\")\n",
    "    elif data is np.ndarray:\n",
    "        raise TypeError(\"input data should be numpy.ndarray\")\n",
    "    elif data.shape[0] < batch_size:\n",
    "        raise TypeError(\"please reduce the batch_size less than the data number\")\n",
    "    number_of_batch = data.shape[0]//batch_size\n",
    "    if batch_num >= number_of_batch:\n",
    "        end_of_batch = True\n",
    "    else:\n",
    "        end_of_batch = False\n",
    "    batch_num = batch_num % number_of_batch\n",
    "    return data[batch_num*batch_size:(batch_num+1)*batch_size], end_of_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(train_x, train_y, hps, restore=False, save=False, path=\"./trained_model\", filename=\"model.ckpt\"):\n",
    "    tf.reset_default_graph()\n",
    "    with tf.Session() as sess:\n",
    "        inputs = tf.placeholder(tf.float32, shape=(None, hps.image_dim, hps.image_dim))\n",
    "        labels = tf.placeholder(tf.int32, shape=(None))\n",
    "        logits = cnn_model(inputs)\n",
    "        loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=hps.learning_rate).minimize(loss)\n",
    "        saver = tf.train.Saver()\n",
    "\n",
    "        sess.run([tf.global_variables_initializer()])\n",
    "        if restore:\n",
    "            saver.restore(sess, \"{0}/{1}\".format(path, filename))\n",
    "\n",
    "        for epoch in range(hps.epoch_num):\n",
    "            next_batch = hps.next_batch\n",
    "            while True:\n",
    "                train_data, end_of_batch = get_batch(train_x, batch_size=hps.batch_size, batch_num=next_batch)\n",
    "                train_labels, _ = get_batch(train_y, batch_size=hps.batch_size, batch_num=next_batch)\n",
    "                next_batch += 1\n",
    "                sess.run(optimizer, feed_dict={inputs: train_data, labels: train_labels})\n",
    "                loss_run_time = sess.run(loss, feed_dict={inputs: train_data, labels: train_labels})\n",
    "                if end_of_batch:\n",
    "                    break\n",
    "            print(\"Epoch: {}, Loss:{}\".format(epoch, loss_run_time))\n",
    "        if save:\n",
    "            save_path = saver.save(sess, \"{0}/{1}\".format(path, filename))\n",
    "            print(\"Model is saved to {0}\".format(save_path))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(eval_x, eval_y, hps, path=\"./trained_model\", filename=\"model.ckpt\"):\n",
    "    tf.reset_default_graph()\n",
    "    with tf.Session() as sess:\n",
    "        inputs = tf.placeholder(tf.float32, shape=(None, image_dim, image_dim))\n",
    "        labels = tf.placeholder(tf.int32, shape=(None))\n",
    "        logits = cnn_model(inputs, training=False)\n",
    "        loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
    "        saver = tf.train.Saver()\n",
    "        sess.run([tf.global_variables_initializer()])\n",
    "        saver.restore(sess, \"./trained_model/model.ckpt\")\n",
    "        loss_run_time, logits_run_time = sess.run([loss, logits], feed_dict={inputs: eval_x, labels: eval_y})\n",
    "        accuracy = 100 * np.sum(np.argmax(logits_run_time, axis=1) == eval_y) / eval_y.shape[0]\n",
    "        print(\"Loss:{}, Accuracy:{}%\".format(loss_run_time, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uniform_perturbation(sample, x_min, x_max, n=1, sigma=1, seed=0):\n",
    "    import torch\n",
    "    sample_x = torch.tensor(sample_x)\n",
    "    prior = dist.Uniform(low=torch.max(sample_x-sigma, torch.tensor([x_min])), high=torch.min(sample_x+sigma, torch.tensor([x_max])))\n",
    "    x = prior.sample(torch.Size([n]))\n",
    "    return x.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The bounds in NN-space\n",
    "x_min = (0-0.1307)/0.3081\n",
    "x_max = (1-0.1307)/0.3081"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_idx = random.randrange(0, eval_x.shape[0])\n",
    "sample_x, sample_y = eval_x[sample_idx], eval_y[sample_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_quantile = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "extract = np.array([logits[idx][label] for idx,label in enumerate(train_labels)])\n",
    "-np.log(np.exp(extract+2)/np.exp(logits+2).sum(axis=1)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits.shape\n",
    "labels_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_perturbation(inputs, mean=0, stddev=0.3, seed=0):\n",
    "    perturbation = tf.random.normal(shape,mean=0.0,stddev=1.0,dtype=tf.dtypes.float32,seed=None,name=\"pertubation\")\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The bounds in NN-space\n",
    "x_min = (0-0.1307)/0.3081\n",
    "x_max = (1-0.1307)/0.3081"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Below are Testing </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_quantile = 0.1\n",
    "termination_threshold = math.exp(-250)\n",
    "MH_steps = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_perturbation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_perturbation(inputs, mean=0, stddev=0.3, seed=0):\n",
    "    perturbation = tf.random.normal(shape,mean=0.0,stddev=1.0,dtype=tf.dtypes.float32,seed=None,name=\"pertubation\")\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_perturbation(data, mean=0, sd=0.3):\n",
    "    perturbation = np.random.normal(loc=mean, scale=sd, size=data.shape)\n",
    "    return data+perturbation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_perturbation(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proposal(x_prior=0):\n",
    "    return scipy.stats.norm(x_prior,1).rvs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def real_density(x):\n",
    "    if x > 1 or x < 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proposal_ratio(x, x_prior):\n",
    "    x_prior_against_x = scipy.stats.norm(x,1).pdf(x_prior)\n",
    "    x_against_x_prior = scipy.stats.norm(x_prior,1).pdf(x)\n",
    "    return x_prior_against_x/x_against_x_prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def real_density_ratio(x, x_prior):\n",
    "    if x_prior < 0 or x_prior > 1:\n",
    "        return 1e10\n",
    "    else:\n",
    "        return real_density(x)/real_density(x_prior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = 100000\n",
    "x = proposal(3)\n",
    "result = []\n",
    "for i in range(M):\n",
    "    result += [x]\n",
    "    x_new = proposal(x)\n",
    "    alpha = min(1, proposal_ratio(x_new, x)*real_density_ratio(x_new, x))\n",
    "    u = random.random()\n",
    "    if u < alpha:\n",
    "        x = x_new\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([4761., 4597., 4488., 4579., 4396., 4345., 4528., 4670., 4431.,\n",
       "        4598., 4323., 4396., 4485., 4503., 4396., 4418., 4367., 4580.,\n",
       "        4515., 4624.]),\n",
       " array([7.02345968e-05, 5.00656996e-02, 1.00061165e-01, 1.50056630e-01,\n",
       "        2.00052095e-01, 2.50047560e-01, 3.00043025e-01, 3.50038490e-01,\n",
       "        4.00033955e-01, 4.50029420e-01, 5.00024885e-01, 5.50020350e-01,\n",
       "        6.00015815e-01, 6.50011280e-01, 7.00006745e-01, 7.50002210e-01,\n",
       "        7.99997675e-01, 8.49993140e-01, 8.99988605e-01, 9.49984070e-01,\n",
       "        9.99979535e-01]),\n",
       " <a list of 20 Patch objects>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAEF1JREFUeJzt3X+s3fVdx/Hna3RsyuZgoxDSVotZl40tccMGapboNpZSOkP5A0wXJx1pbDLRTF1Upn+gMJJNoxiS/apCVhY3wOmkmSg2/MjUCOMiG+OHpHcMoSlZO1uqCxkKe/vH+ZRd2L295/aee25vP89HcnO+3/f38z3fz6f33PM63x/n21QVkqT+vGKxOyBJWhwGgCR1ygCQpE4ZAJLUKQNAkjplAEhSp4YKgCRPJPlmkq8nmWi11yfZlWR3ezyl1ZPkuiSTSR5McvaU59nS2u9OsmVhhiRJGsZc9gDeXVVvr6q1bf4K4I6qWgPc0eYBLgDWtJ9twKdhEBjAlcC5wDnAlYdDQ5I0fvM5BLQJ2NGmdwAXTanfWAP3ACcnOQM4H9hVVQeq6iCwC9gwj+1LkuZh2ZDtCvinJAV8tqq2A6dX1dMAVfV0ktNa2xXAU1PW3dNqM9VfIsk2BnsOnHTSST/75je/eQ7DkSTdf//9362q5bO1GzYA3llVe9ub/K4k/3GEtpmmVkeov7QwCJftAGvXrq2JiYkhuyhJAkjyn8O0G+oQUFXtbY/7gC8zOIb/nXZoh/a4rzXfA6yasvpKYO8R6pKkRTBrACQ5KclrD08D64GHgJ3A4St5tgC3tumdwKXtaqB1wKF2qOh2YH2SU9rJ3/WtJklaBMMcAjod+HKSw+2/UFX/mOQ+4JYkW4EngUta+9uAjcAk8CxwGUBVHUhyNXBfa3dVVR0Y2UgkSXOSY/l20J4DkKS5S3L/lEv2Z+Q3gSWpUwaAJHXKAJCkThkAktQpA0CSOjXsN4GXpNVX/P1Rr/vEx983wp5I0rHHPQBJ6pQBIEmdMgAkqVPH9TkALQ2eq5EWh3sAktQp9wAkaYEc63u3BsAMjvVfnEbD37N6ZgAcY3xDkkbLv6mZeQ5AkjrlHoBGYj6fsqRj1fH+ujYApI7M9w3teD8k0hsDYAEc758atLh8fWlUPAcgSZ1yD0BLmp+GpaNnAEgaCy/HPPYYAMcRT/AtHUt1z2Wp9lvTMwAkHfMMnoVhAOhF/pFJfTEApKNkYGqp8zJQSeqUASBJnTIAJKlTBoAkdcoAkKROGQCS1CkDQJI6ZQBIUqcMAEnqlAEgSZ0aOgCSnJDkgSRfafNnJrk3ye4kNyc5sdVf1eYn2/LVU57jo63+WJLzRz0YSdLw5rIH8GHg0SnznwCurao1wEFga6tvBQ5W1RuBa1s7kpwFbAbeCmwAPpXkhPl1X5J0tIYKgCQrgfcBf9nmA7wH+FJrsgO4qE1vavO05ee19puAm6rquar6NjAJnDOKQUiS5m7YPYA/B34X+EGbfwPwTFU93+b3ACva9ArgKYC2/FBr/2J9mnVelGRbkokkE/v375/DUCRJczFrACT5RWBfVd0/tTxN05pl2ZHW+WGhantVra2qtcuXL5+te5KkozTM/wfwTuDCJBuBVwM/wWCP4OQky9qn/JXA3tZ+D7AK2JNkGfA64MCU+mFT15EkjdmsewBV9dGqWllVqxmcxL2zqn4ZuAu4uDXbAtzapne2edryO6uqWn1zu0roTGAN8LWRjUSSNCfz+R/Bfg+4KcnHgAeA61v9euDzSSYZfPLfDFBVDye5BXgEeB64vKpemMf2JUnzMKcAqKq7gbvb9ONMcxVPVX0fuGSG9a8BrplrJyVJo+c3gSWpUwaAJHXKAJCkThkAktQpA0CSOmUASFKnDABJ6pQBIEmdMgAkqVMGgCR1ygCQpE4ZAJLUKQNAkjplAEhSpwwASeqUASBJnTIAJKlTBoAkdcoAkKROGQCS1CkDQJI6ZQBIUqcMAEnqlAEgSZ0yACSpUwaAJHXKAJCkThkAktQpA0CSOmUASFKnDABJ6pQBIEmdMgAkqVMGgCR1atYASPLqJF9L8o0kDyf5o1Y/M8m9SXYnuTnJia3+qjY/2ZavnvJcH231x5Kcv1CDkiTNbpg9gOeA91TVzwBvBzYkWQd8Ari2qtYAB4Gtrf1W4GBVvRG4trUjyVnAZuCtwAbgU0lOGOVgJEnDmzUAauB7bfaV7aeA9wBfavUdwEVtelObpy0/L0la/aaqeq6qvg1MAueMZBSSpDkb6hxAkhOSfB3YB+wCvgU8U1XPtyZ7gBVtegXwFEBbfgh4w9T6NOtM3da2JBNJJvbv3z/3EUmShjJUAFTVC1X1dmAlg0/tb5muWXvMDMtmqr98W9uram1VrV2+fPkw3ZMkHYU5XQVUVc8AdwPrgJOTLGuLVgJ72/QeYBVAW/464MDU+jTrSJLGbJirgJYnOblN/xjwXuBR4C7g4tZsC3Brm97Z5mnL76yqavXN7SqhM4E1wNdGNRBJ0twsm70JZwA72hU7rwBuqaqvJHkEuCnJx4AHgOtb++uBzyeZZPDJfzNAVT2c5BbgEeB54PKqemG0w5EkDWvWAKiqB4F3TFN/nGmu4qmq7wOXzPBc1wDXzL2bkqRR85vAktQpA0CSOmUASFKnDABJ6pQBIEmdMgAkqVMGgCR1ygCQpE4ZAJLUKQNAkjplAEhSpwwASeqUASBJnTIAJKlTBoAkdcoAkKROGQCS1CkDQJI6ZQBIUqcMAEnqlAEgSZ0yACSpUwaAJHXKAJCkThkAktQpA0CSOmUASFKnDABJ6pQBIEmdMgAkqVMGgCR1ygCQpE4ZAJLUKQNAkjplAEhSp2YNgCSrktyV5NEkDyf5cKu/PsmuJLvb4ymtniTXJZlM8mCSs6c815bWfneSLQs3LEnSbIbZA3ge+EhVvQVYB1ye5CzgCuCOqloD3NHmAS4A1rSfbcCnYRAYwJXAucA5wJWHQ0OSNH6zBkBVPV1V/96m/wd4FFgBbAJ2tGY7gIva9Cbgxhq4Bzg5yRnA+cCuqjpQVQeBXcCGkY5GkjS0OZ0DSLIaeAdwL3B6VT0Ng5AATmvNVgBPTVltT6vNVH/5NrYlmUgysX///rl0T5I0B0MHQJLXAH8D/GZV/feRmk5TqyPUX1qo2l5Va6tq7fLly4ftniRpjoYKgCSvZPDm/1dV9bet/J12aIf2uK/V9wCrpqy+Eth7hLokaREMcxVQgOuBR6vqz6Ys2gkcvpJnC3DrlPql7WqgdcChdojodmB9klPayd/1rSZJWgTLhmjzTuBXgG8m+Xqr/T7wceCWJFuBJ4FL2rLbgI3AJPAscBlAVR1IcjVwX2t3VVUdGMkoJElzNmsAVNW/MP3xe4DzpmlfwOUzPNcNwA1z6aAkaWH4TWBJ6pQBIEmdMgAkqVMGgCR1ygCQpE4ZAJLUKQNAkjplAEhSpwwASeqUASBJnTIAJKlTBoAkdcoAkKROGQCS1CkDQJI6ZQBIUqcMAEnqlAEgSZ0yACSpUwaAJHXKAJCkThkAktQpA0CSOmUASFKnDABJ6pQBIEmdMgAkqVMGgCR1ygCQpE4ZAJLUKQNAkjplAEhSpwwASeqUASBJnZo1AJLckGRfkoem1F6fZFeS3e3xlFZPkuuSTCZ5MMnZU9bZ0trvTrJlYYYjSRrWMHsAnwM2vKx2BXBHVa0B7mjzABcAa9rPNuDTMAgM4ErgXOAc4MrDoSFJWhyzBkBVfRU48LLyJmBHm94BXDSlfmMN3AOcnOQM4HxgV1UdqKqDwC5+NFQkSWN0tOcATq+qpwHa42mtvgJ4akq7Pa02U/1HJNmWZCLJxP79+4+ye5Kk2Yz6JHCmqdUR6j9arNpeVWurau3y5ctH2jlJ0g8dbQB8px3aoT3ua/U9wKop7VYCe49QlyQtkqMNgJ3A4St5tgC3Tqlf2q4GWgccaoeIbgfWJzmlnfxd32qSpEWybLYGSb4IvAs4NckeBlfzfBy4JclW4Engktb8NmAjMAk8C1wGUFUHklwN3NfaXVVVLz+xLEkao1kDoKreP8Oi86ZpW8DlMzzPDcANc+qdJGnB+E1gSeqUASBJnTIAJKlTBoAkdcoAkKROGQCS1CkDQJI6ZQBIUqcMAEnqlAEgSZ0yACSpUwaAJHXKAJCkThkAktQpA0CSOmUASFKnDABJ6pQBIEmdMgAkqVMGgCR1ygCQpE4ZAJLUKQNAkjplAEhSpwwASeqUASBJnTIAJKlTBoAkdcoAkKROGQCS1CkDQJI6ZQBIUqcMAEnqlAEgSZ0yACSpU2MPgCQbkjyWZDLJFePeviRpYKwBkOQE4JPABcBZwPuTnDXOPkiSBsa9B3AOMFlVj1fV/wI3AZvG3AdJErBszNtbATw1ZX4PcO7UBkm2Adva7PeSPDaP7Z0KfHce6y81vY0XHHMvuhtzPjGvMf/UMI3GHQCZplYvmanaDmwfycaSiapaO4rnWgp6Gy845l445oUx7kNAe4BVU+ZXAnvH3AdJEuMPgPuANUnOTHIisBnYOeY+SJIY8yGgqno+ya8DtwMnADdU1cMLuMmRHEpaQnobLzjmXjjmBZCqmr2VJOm44zeBJalTBoAkdWrJB8Bst5ZI8qokN7fl9yZZPf5ejtYQY/7tJI8keTDJHUmGuib4WDbsLUSSXJykkiz5SwaHGXOSX2q/64eTfGHcfRy1IV7bP5nkriQPtNf3xsXo56gkuSHJviQPzbA8Sa5r/x4PJjl7pB2oqiX7w+BE8reAnwZOBL4BnPWyNr8GfKZNbwZuXux+j2HM7wZ+vE1/qIcxt3avBb4K3AOsXex+j+H3vAZ4ADilzZ+22P0ew5i3Ax9q02cBTyx2v+c55p8HzgYemmH5RuAfGHyHah1w7yi3v9T3AIa5tcQmYEeb/hJwXpLpvpC2VMw65qq6q6qebbP3MPi+xVI27C1Ergb+GPj+ODu3QIYZ868Cn6yqgwBVtW/MfRy1YcZcwE+06dexxL9HVFVfBQ4cockm4MYauAc4OckZo9r+Ug+A6W4tsWKmNlX1PHAIeMNYercwhhnzVFsZfIJYymYdc5J3AKuq6ivj7NgCGub3/CbgTUn+Nck9STaMrXcLY5gx/yHwgSR7gNuA3xhP1xbNXP/e52Tct4IYtVlvLTFkm6Vk6PEk+QCwFviFBe3RwjvimJO8ArgW+OC4OjQGw/yelzE4DPQuBnt5/5zkbVX1zAL3baEMM+b3A5+rqj9N8nPA59uYf7Dw3VsUC/r+tdT3AIa5tcSLbZIsY7DbeKRdrmPdULfTSPJe4A+AC6vquTH1baHMNubXAm8D7k7yBINjpTuX+IngYV/bt1bV/1XVt4HHGATCUjXMmLcCtwBU1b8Br2Zwo7jj1YLePmepB8Awt5bYCWxp0xcDd1Y7u7JEzTrmdjjkswze/Jf6cWGYZcxVdaiqTq2q1VW1msF5jwuramJxujsSw7y2/47BCX+SnMrgkNDjY+3laA0z5ieB8wCSvIVBAOwfay/HaydwabsaaB1wqKqeHtWTL+lDQDXDrSWSXAVMVNVO4HoGu4mTDD75b168Hs/fkGP+E+A1wF+3891PVtWFi9bpeRpyzMeVIcd8O7A+ySPAC8DvVNV/LV6v52fIMX8E+Iskv8XgUMgHl/IHuiRfZHAI79R2XuNK4JUAVfUZBuc5NgKTwLPAZSPd/hL+t5MkzcNSPwQkSTpKBoAkdcoAkKROGQCS1CkDQJI6ZQBIUqcMAEnq1P8DveScdgidS88AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "plt.hist(result[10000:], bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (flo)",
   "language": "python",
   "name": "florence"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
